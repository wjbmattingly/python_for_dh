{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-celebration",
   "metadata": {},
   "source": [
    "# <center>Working with Multiple Files</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-citation",
   "metadata": {},
   "source": [
    "<center>Dr. W.J.B. Mattingly</center>\n",
    "\n",
    "<center>Smithsonian Data Science Lab and United States Holocaust Memorial Museum</center>\n",
    "\n",
    "<center>March 2022</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-france",
   "metadata": {},
   "source": [
    "## Covered in this Chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-bones",
   "metadata": {},
   "source": [
    "1) The glob library<br>\n",
    "2) Working with os<br>\n",
    "3) Walking Directories<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-giant",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-greeting",
   "metadata": {},
   "source": [
    "Often times, it is necessary to open multiple files in a Python script. There are multiple ways to do this, but unlike most Python textbooks. I recommend that beginners use the library called glob. <b>Glob</b> comes standard with Python which means you do not have to install it. A good way to think about glob is as a library that allows you to look into a directory and find all potential files based on certain parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-physiology",
   "metadata": {},
   "source": [
    "## Working with Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-tourist",
   "metadata": {},
   "source": [
    "Working with glob can be a little confusing at first, but let's break it down. First, we need to import glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regional-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-movement",
   "metadata": {},
   "source": [
    "Next, we need to use the glob class. This will take one argument, the string of files that you want to find. Let's use the data subfolder as an example. In the example below, we pass one string to this class. This string will be the subfolder in which the data lies followed by a slash followed by an \\*. This \\* is known as a wild card. In our case, it looks for all files within this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-frame",
   "metadata": {},
   "source": [
    "Let's print off the files now to see what all is inside the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secure-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/other2', 'data/sample_json.json', 'data/other', 'data/sample2.txt', 'data/sample.txt']\n"
     ]
    }
   ],
   "source": [
    "print (files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49886f41-8eec-4150-8f20-d5641e747a3c",
   "metadata": {},
   "source": [
    "Notice that we have grabbed all files! Most of the time, however, you will only want to grab files that are a specific type, e.g. .txt or .json. To achieve this we can add a .txt after the \\*. This will grab all the .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a1e785-03bd-4d05-8e74-04acec91c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/sample2.txt', 'data/sample.txt']\n"
     ]
    }
   ],
   "source": [
    "files2 = glob.glob(\"data/*.txt\")\n",
    "print (files2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-antique",
   "metadata": {},
   "source": [
    "## Grabbing Multiple Nested Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a82138-c4bb-4411-aace-94e2c8a271ef",
   "metadata": {},
   "source": [
    "If you look in the subdirectory data, you will notice two nested directories called \"other\" and \"other2\". We can grab all files in each directory with the same wildcard \\*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea28b8d-70ea-4f3f-ac4f-b4ba97a48213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/other2/sample4.txt', 'data/other/sample3.txt']\n"
     ]
    }
   ],
   "source": [
    "files3 = glob.glob(\"data/*/*.txt\")\n",
    "print (files3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-milwaukee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Walking a Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-capital",
   "metadata": {},
   "source": [
    "While glob is easy-to-use, it has certain limitations. One of these is when you need to walk through a directory. Imagine if we needed to grab all the txt files in data, data/other and data/other2. In order to grab all of these, we need to walk through all the subdirectories of data and collect all potential files. This is not possible to do with glob. In these rare circumstances, you should be familiar with the os library.\n",
    "\n",
    "The <b>os</b> library allows us to do a lot of more advanced things in Python that I will not cover in this introductory textbook. One of the main things you will use os for is to navigate directories and create directories. For Linux users, a lot of the syntax will be familiar, but for Windows users it can feel a bit foreign. For now, let's simply import os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plain-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-element",
   "metadata": {},
   "source": [
    "Once we have imported os, we can use the os.walk command. This will take one string. This should correspond to the directory that you want to start walking. Imagine that this is our directory:\n",
    "\n",
    "- data\n",
    "    - other\n",
    "    - other2\n",
    "\n",
    "We want to get all the text files in data, other, and other2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-provincial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x7f40f704ad60>\n"
     ]
    }
   ],
   "source": [
    "walking = os.walk(\"data/\")\n",
    "print (walking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952614b-a0df-4dc6-abb5-a455eb0a9a3e",
   "metadata": {},
   "source": [
    "This above output tells us what what we are looking at is a generator. Generators are a bit beyond this textbook, but think of them as a special kind of object that exists for a single moment in memory. Whenever you see generators, you can usually convert them to a list to work with them. Let's convert it by using the list() function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convertible-arrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data/', ['other2', 'other', '.ipynb_checkpoints'], ['sample_json.json', 'sample2.txt', 'sample.txt']), ('data/other2', ['.ipynb_checkpoints'], ['sample4.txt']), ('data/other2/.ipynb_checkpoints', [], []), ('data/other', ['.ipynb_checkpoints'], ['sample3.txt']), ('data/other/.ipynb_checkpoints', [], []), ('data/.ipynb_checkpoints', [], ['sample2-checkpoint.txt', 'sample_json-checkpoint.json', 'sample-checkpoint.txt'])]\n"
     ]
    }
   ],
   "source": [
    "walking = list(walking)\n",
    "print (walking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c015066-7112-479f-9315-e9abfd3b2894",
   "metadata": {},
   "source": [
    "This can be a bit diffult to parse, so let's iterate over each item in walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b58ade-acdd-4077-9c79-01ab420f1fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/', ['other2', 'other', '.ipynb_checkpoints'], ['sample_json.json', 'sample2.txt', 'sample.txt'])\n",
      "('data/other2', ['.ipynb_checkpoints'], ['sample4.txt'])\n",
      "('data/other2/.ipynb_checkpoints', [], [])\n",
      "('data/other', ['.ipynb_checkpoints'], ['sample3.txt'])\n",
      "('data/other/.ipynb_checkpoints', [], [])\n",
      "('data/.ipynb_checkpoints', [], ['sample2-checkpoint.txt', 'sample_json-checkpoint.json', 'sample-checkpoint.txt'])\n"
     ]
    }
   ],
   "source": [
    "for item in walking:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951bd73-ddc9-4439-8087-4da5abf30d80",
   "metadata": {},
   "source": [
    "As we can see, each item is a tuple with 3 parts:\n",
    "\n",
    "- root directory\n",
    "- subfolders\n",
    "- files\n",
    "\n",
    "For our purposes, we only care about the root directory and the file itself. We can use these two pieces of data. Let's now modify our loop to grab these two pieces of data and print them off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a47d2b-632a-4c31-b405-d24870b97020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Root\n",
      "data/\n",
      "These are the Files\n",
      "['sample_json.json', 'sample2.txt', 'sample.txt']\n",
      "\n",
      "\n",
      "This is the Root\n",
      "data/other2\n",
      "These are the Files\n",
      "['sample4.txt']\n",
      "\n",
      "\n",
      "This is the Root\n",
      "data/other2/.ipynb_checkpoints\n",
      "These are the Files\n",
      "[]\n",
      "\n",
      "\n",
      "This is the Root\n",
      "data/other\n",
      "These are the Files\n",
      "['sample3.txt']\n",
      "\n",
      "\n",
      "This is the Root\n",
      "data/other/.ipynb_checkpoints\n",
      "These are the Files\n",
      "[]\n",
      "\n",
      "\n",
      "This is the Root\n",
      "data/.ipynb_checkpoints\n",
      "These are the Files\n",
      "['sample2-checkpoint.txt', 'sample_json-checkpoint.json', 'sample-checkpoint.txt']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_files = []\n",
    "for item in walking:\n",
    "    root = item[0]\n",
    "    files = item[2]\n",
    "    print (\"This is the Root\")\n",
    "    print (root)\n",
    "    print (\"These are the Files\")\n",
    "    print (files)\n",
    "    print ()\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfb687-9138-4824-896c-49ed2feb8375",
   "metadata": {},
   "source": [
    "As we can see, the files are a list. We can then iterate over the files to recombine the root with the files to cultivate a list. With os, we can do this with os.path.join(). This will take two arguments, the root directory and the file. Let's again modify our loop. We will print off the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b96c61-1795-474a-bae3-c6559cfc06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sample2.txt\n",
      "data/sample.txt\n",
      "data/other2/sample4.txt\n",
      "data/other/sample3.txt\n",
      "data/.ipynb_checkpoints/sample2-checkpoint.txt\n",
      "data/.ipynb_checkpoints/sample-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "for item in walking:\n",
    "    root = item[0]\n",
    "    files = item[2]\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5608225-8338-4cf0-95c3-704ad2ba96e0",
   "metadata": {},
   "source": [
    "Excellent! Now, we can use this exact same loop to append the file names to an empty list called final_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ongoing-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/sample2.txt', 'data/sample.txt', 'data/other2/sample4.txt', 'data/other/sample3.txt', 'data/.ipynb_checkpoints/sample2-checkpoint.txt', 'data/.ipynb_checkpoints/sample-checkpoint.txt']\n"
     ]
    }
   ],
   "source": [
    "final_files = []\n",
    "for item in walking:\n",
    "    root = item[0]\n",
    "    files = item[2]\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             final_files.append(os.path.join(root, file))\n",
    "print (final_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187ed28-f092-42f3-9cac-f919bf04dd28",
   "metadata": {},
   "source": [
    "Notice that we now have all the .txt files in the main directory and all subdirectories. This will be very useful when your files are in multiple subdirectories within multiple subdirectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9094027-ed49-443f-b928-54ee4d2f6032",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46daaf-115d-49e0-9aa6-69aceb9f86c2",
   "metadata": {},
   "source": [
    "I would recommend playing around with the code provided to you in this chapter. I cannot emphasize enough how frequently you will need to work with multiple files in a Python project. It is perhaps one of the things you should work hard to commit to memory. Over time, it will become more instinctual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe703d-18b8-4435-bc31-544dec4aea98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
